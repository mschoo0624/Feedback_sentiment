{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93605eaf",
   "metadata": {},
   "source": [
    "# ü§ñ Sarcasm + Sentiment Classification\n",
    "This notebook trains a binary classifier to distinguish sarcastic or negative feedback from genuine positive feedback.\n",
    "\n",
    "It combines:\n",
    "- Sarcasm-labeled tweets (`tweet_eval`)\n",
    "- Sentiment-labeled product reviews (`amazon_polarity`)\n",
    "\n",
    "And uses a memory-optimized setup for Apple M1 8GB machines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d7abf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üì¶ Install dependencies (if needed)\n",
    "# !pip install transformers datasets scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3e2311",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìö Import libraries\n",
    "import random\n",
    "import logging\n",
    "import os\n",
    "from typing import List, Dict\n",
    "from datasets import load_dataset, Dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    DataCollatorWithPadding,\n",
    ")\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31fd563",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üß† Device configuration for Apple M1 or fallback to CPU\n",
    "os.environ[\"PYTORCH_ENABLE_MPS_FALLBACK\"] = \"1\"\n",
    "os.environ[\"PYTORCH_MPS_HIGH_WATERMARK_RATIO\"] = \"0.0\"\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    torch_device = torch.device(\"mps\")\n",
    "    logger.info(\"Using device: MPS (Apple Silicon)\")\n",
    "elif torch.cuda.is_available():\n",
    "    torch_device = torch.device(\"cuda\")\n",
    "    logger.info(\"Using device: CUDA\")\n",
    "else:\n",
    "    torch_device = torch.device(\"cpu\")\n",
    "    logger.info(\"Using device: CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6143a787",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üì• Load and preprocess the dataset (reduced size for M1 memory)\n",
    "def pre_labeled_datasets() -> List[Dict]:\n",
    "    logger.info(\"Loading datasets with 8GB M1 optimizations...\")\n",
    "    sarcasm_ds = load_dataset(\"tweet_eval\", \"irony\")\n",
    "    sentiment_ds = load_dataset(\"amazon_polarity\")\n",
    "\n",
    "    data = []\n",
    "    sarcasm_subset = sarcasm_ds[\"train\"].select(range(2000))\n",
    "    for example in sarcasm_subset:\n",
    "        text = example[\"text\"]\n",
    "        if len(text) > 200: continue\n",
    "        label = \"Dislike\" if example[\"label\"] == 1 else \"Like\"\n",
    "        data.append({\"text\": text, \"label\": label})\n",
    "\n",
    "    sentiment_subset = sentiment_ds[\"train\"].select(range(2000))\n",
    "    for example in sentiment_subset:\n",
    "        text = example.get(\"content\") or example.get(\"text\") or example.get(\"review\") or list(example.values())[0]\n",
    "        if len(text) > 200: continue\n",
    "        label = \"Like\" if example[\"label\"] == 1 else \"Dislike\"\n",
    "        data.append({\"text\": text, \"label\": label})\n",
    "\n",
    "    random.shuffle(data)\n",
    "    logger.info(f\"Total dataset size after filtering: {len(data)} examples\")\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039af85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üè∑Ô∏è Map labels to numerical values for classification\n",
    "LABEL_MAP = {\"Dislike\": 0, \"Like\": 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49aa69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÇÔ∏è Tokenization function (optimized with max_length=64 for memory)\n",
    "def tokenize(example, tokenizer):\n",
    "    encoding = tokenizer(\n",
    "        example['text'],\n",
    "        truncation=True,\n",
    "        padding=False,\n",
    "        max_length=64\n",
    "    )\n",
    "    encoding['label'] = LABEL_MAP[example['label']]\n",
    "    return encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d169a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ Define evaluation metrics (Accuracy & F1 Score)\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = torch.argmax(torch.tensor(logits), dim=-1)\n",
    "    acc = accuracy_score(labels, predictions)\n",
    "    f1 = f1_score(labels, predictions)\n",
    "    return {\"accuracy\": acc, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7e0706",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üöÄ Main training function\n",
    "def train_model(model_name: str = \"distilbert-base-uncased\"):\n",
    "    if torch.backends.mps.is_available():\n",
    "        torch.mps.empty_cache()\n",
    "\n",
    "    raw_data = pre_labeled_datasets()\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    dataset = Dataset.from_list(raw_data)\n",
    "    dataset = dataset.map(lambda x: tokenize(x, tokenizer), batched=False, remove_columns=['text'])\n",
    "\n",
    "    dataset = dataset.train_test_split(test_size=0.2)\n",
    "    train_dataset = dataset[\"train\"]\n",
    "    eval_dataset = dataset[\"test\"]\n",
    "\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2, torch_dtype=torch.float32)\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=\"./results\",\n",
    "        eval_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        learning_rate=3e-5,\n",
    "        per_device_train_batch_size=1,\n",
    "        per_device_eval_batch_size=1,\n",
    "        gradient_accumulation_steps=8,\n",
    "        num_train_epochs=2,\n",
    "        weight_decay=0.01,\n",
    "        logging_dir=\"./logs\",\n",
    "        logging_steps=50,\n",
    "        report_to=\"none\",\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"f1\",\n",
    "        greater_is_better=True,\n",
    "        dataloader_pin_memory=False,\n",
    "        dataloader_num_workers=0,\n",
    "        remove_unused_columns=True,\n",
    "        save_total_limit=1,\n",
    "        fp16=False,\n",
    "        eval_accumulation_steps=1,\n",
    "        prediction_loss_only=False,\n",
    "    )\n",
    "\n",
    "    trainer_obj = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=eval_dataset,\n",
    "        processing_class=tokenizer,\n",
    "        compute_metrics=compute_metrics,\n",
    "        data_collator=DataCollatorWithPadding(tokenizer, pad_to_multiple_of=None)\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        if torch.backends.mps.is_available():\n",
    "            torch.mps.empty_cache()\n",
    "        trainer_obj.train()\n",
    "        print(\"\\nüìà Evaluating model...\")\n",
    "        metrics = trainer_obj.evaluate()\n",
    "        print(\"\\n‚úÖ Evaluation Results:\", metrics)\n",
    "\n",
    "        print(\"\\nüíæ Saving final model to ./sarcasm_sentiment_model\")\n",
    "        model.save_pretrained(\"./sarcasm_sentiment_model\")\n",
    "        tokenizer.save_pretrained(\"./sarcasm_sentiment_model\")\n",
    "    except RuntimeError as e:\n",
    "        if \"out of memory\" in str(e).lower():\n",
    "            print(\"\\n‚ö†Ô∏è MPS memory error: retrying on CPU\")\n",
    "            train_model_cpu_fallback()\n",
    "        else:\n",
    "            raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6483274",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üß† CPU fallback training (for extreme low-memory cases)\n",
    "def train_model_cpu_fallback():\n",
    "    torch_device = torch.device(\"cpu\")\n",
    "    model_name = \"prajjwal1/bert-tiny\"\n",
    "    raw_data = pre_labeled_datasets()\n",
    "    raw_data = random.sample(raw_data, min(len(raw_data), 2000))\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    dataset = Dataset.from_list(raw_data)\n",
    "    dataset = dataset.map(lambda x: tokenize(x, tokenizer), remove_columns=['text'])\n",
    "    dataset = dataset.train_test_split(test_size=0.2)\n",
    "\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "    model.to(torch_device)\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=\"./results\",\n",
    "        eval_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        learning_rate=5e-5,\n",
    "        per_device_train_batch_size=4,\n",
    "        per_device_eval_batch_size=4,\n",
    "        num_train_epochs=2,\n",
    "        weight_decay=0.01,\n",
    "        logging_dir=\"./logs\",\n",
    "        logging_steps=50,\n",
    "        report_to=\"none\",\n",
    "        load_best_model_at_end=True,\n",
    "        save_total_limit=1,\n",
    "    )\n",
    "\n",
    "    trainer_obj = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=dataset[\"train\"],\n",
    "        eval_dataset=dataset[\"test\"],\n",
    "        processing_class=tokenizer,\n",
    "        compute_metrics=compute_metrics,\n",
    "        data_collator=DataCollatorWithPadding(tokenizer)\n",
    "    )\n",
    "\n",
    "    trainer_obj.train()\n",
    "    metrics = trainer_obj.evaluate()\n",
    "    print(\"\\n‚úÖ Evaluation Results (CPU):\", metrics)\n",
    "\n",
    "    model.save_pretrained(\"./sarcasm_sentiment_model\")\n",
    "    tokenizer.save_pretrained(\"./sarcasm_sentiment_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4763b7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ Run training\n",
    "train_model()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
